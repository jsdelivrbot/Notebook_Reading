# 集成学习 Ensemble learning

## 集成学习：概念

- 定义：构建并结合多个学习器
- 别名： multi-classifier system / committee-based learning
- 分类
  - homogeneous:只包括同种类型的个体学习器
    - 基学习器
    - 基学习算法 base learning algorithm
  - heterogenous:包括由不同学习算法生成的
    - 组件学习器 component learner
- 优势：泛化性能好
  - 集成的错误率随分类器数目T增大而下降
  - 基分类器错误率相互独立
  - 集成错误率：二项分布求和

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>

$$x=\frac{-b\pm\sqrt{b^2-4ac}}{2a}$$\\(x=\frac{-b\pm\sqrt{b^2-4ac}}{2a}\\)

## 集成学习：步骤

- 产生一组 individual learner
- 以某种策略将它们结合起来

## 学习器生成方法

- 序列化方法：个体间强依赖(boosting)
- 并行化方法：同时生成(bagging & random forest)

### Boosting

- 步骤
  - 先从初始训练集得出一个基学习器
  - 在根据其表现对训练样本分布进行调整
  - 迭代：直到学习器数目达到T
    - 基学习器做错的训练样本得到更多关注
    - 基于新样本分布训练下一个基学习器
  - 将T个基学习器加权结合
- AdaBoost算法
  - 基于additive model
  - 最小化指数损失函数
  - 数学推导略
- 学习特定的数据分布
  - 重赋权法
  - 重采样法

### Bagging

- 使用训练集的若干个相互交叠的子集作为训练数据
- 自助采样法：从容量m的数据集中有放回地取m个样本
- 简单投票法/简单平均法

### 随机森林

决策树基Bagging集成的一种拓展

在基学习器的多样性中，除样本扰动外，再加入属性扰动。